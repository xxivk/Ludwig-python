{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ludwig    \n",
    "import spacy                                           \n",
    "from ludwig.api import LudwigModel  \n",
    "from ludwig.visualize import learning_curves, compare_performance, compare_classifiers_predictions\n",
    "from ludwig.utils.data_utils import load_json\n",
    "from ludwig.utils.nlp_utils import load_nlp_pipeline, process_text\n",
    "\n",
    "# data and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# dataset utils\n",
    "from torchtext import data                                  \n",
    "from torchtext import datasets   \n",
    "\n",
    "# auxiliary packages\n",
    "import os\n",
    "import yaml                                       \n",
    "import logging                                    \n",
    "import json\n",
    "from tqdm.notebook import trange                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick either SST-2 (False) or SST-5 (True)\n",
    "fine_grained = True\n",
    "\n",
    "if(fine_grained):\n",
    "  # define SST-5 classes for sentiment labels\n",
    "  idx2class = ['very negative', 'negative', 'neutral', 'positive', 'very positive']\n",
    "  class2idx = {cls: idx for idx, cls in enumerate(idx2class)}\n",
    "else:\n",
    "  # define SST-2 classes for sentiment labels\n",
    "  idx2class = [\"negative\", \"neutral\", \"positive\"]\n",
    "  class2idx = {cls: idx for idx, cls in enumerate(idx2class)}\n",
    "\n",
    "text_field = data.Field(sequential=True)\n",
    "label_field = data.Field(sequential=True)  # False means no tokenization\n",
    "\n",
    "# obtain pre-split data into training, validation and testing sets\n",
    "train_split, val_split, test_split = datasets.SST.splits(\n",
    "    text_field,\n",
    "    label_field,\n",
    "    fine_grained=fine_grained,\n",
    "    train_subtrees=True  # use all subtrees in the training set\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain texts and labels from the training set\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in trange(len(train_split), desc='Train'):\n",
    "    x_train.append(vars(train_split[i])[\"text\"])\n",
    "    y_train.append(class2idx[vars(train_split[i])[\"label\"]])\n",
    "\n",
    "# obtain texts and labels from the validation set\n",
    "x_val = []\n",
    "y_val = []\n",
    "for i in trange(len(val_split), desc='Validation'):\n",
    "    x_val.append(vars(val_split[i])[\"text\"])\n",
    "    y_val.append(class2idx[vars(val_split[i])[\"label\"]])\n",
    "\n",
    "# obtain texts and labels from the test set\n",
    "x_test = []\n",
    "y_test = []\n",
    "for i in trange(len(test_split), desc='Test'):\n",
    "    x_test.append(vars(test_split[i])[\"text\"])\n",
    "    y_test.append(class2idx[vars(test_split[i])[\"label\"]])\n",
    "\n",
    "# create three separate dataframes\n",
    "train_data = pd.DataFrame({\"text\": x_train, \"label\": y_train})\n",
    "validation_data = pd.DataFrame({\"text\": x_val, \"label\": y_val})\n",
    "test_data = pd.DataFrame({\"text\": x_test, \"label\": y_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain texts and labels from the training set\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in trange(len(train_split), desc='Train'):\n",
    "    x_train.append(vars(train_split[i])[\"text\"])\n",
    "    y_train.append(class2idx[vars(train_split[i])[\"label\"]])\n",
    "\n",
    "# obtain texts and labels from the validation set\n",
    "x_val = []\n",
    "y_val = []\n",
    "for i in trange(len(val_split), desc='Validation'):\n",
    "    x_val.append(vars(val_split[i])[\"text\"])\n",
    "    y_val.append(class2idx[vars(val_split[i])[\"label\"]])\n",
    "\n",
    "# obtain texts and labels from the test set\n",
    "x_test = []\n",
    "y_test = []\n",
    "for i in trange(len(test_split), desc='Test'):\n",
    "    x_test.append(vars(test_split[i])[\"text\"])\n",
    "    y_test.append(class2idx[vars(test_split[i])[\"label\"]])\n",
    "\n",
    "# create three separate dataframes\n",
    "train_data = pd.DataFrame({\"text\": x_train, \"label\": y_train})\n",
    "validation_data = pd.DataFrame({\"text\": x_val, \"label\": y_val})\n",
    "test_data = pd.DataFrame({\"text\": x_test, \"label\": y_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [idx2class[int(id)] for id in train_data['label']]\n",
    "\n",
    "train_data_preview = train_data.drop(columns='label').assign(class_id=train_data['label'], class_label=labels)\n",
    "\n",
    "train_data_preview.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting look\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "if fine_grained:\n",
    "  ax.set_title(f'Distribution of sentiment labels in the SST-5 training set')\n",
    "  ax = train_data['label'].value_counts(sort=False).plot(kind='barh', color=['red', 'coral', 'grey', 'lime', 'green'])\n",
    "else:\n",
    "  ax.set_title(f'Distribution of sentiment labels in the SST-2 training set')\n",
    "  ax = train_data['label'].value_counts(sort=False).plot(kind='barh', color=['red','green'])\n",
    "\n",
    "# axes info\n",
    "ax.set_xlabel('Samples in the training set')\n",
    "ax.set_ylabel('Labels')\n",
    "ax.set_yticklabels(tuple(idx2class))\n",
    "ax.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = load_nlp_pipeline('en')\n",
    "nlp = spacy.load('en_core_web_sm', disable = ['parser','ner'])\n",
    "nlp.max_length = 7389814\n",
    "\n",
    "\n",
    "processed_train_data = process_text(' '.join(train_data['text']),\n",
    "                                    load_nlp_pipeline('en'),\n",
    "                                    filter_punctuation=True,\n",
    "                                    filter_stopwords=True)\n",
    "\n",
    "wordcloud = WordCloud(background_color='black', collocations=False,\n",
    "                      stopwords=STOPWORDS).generate(' '.join(processed_train_data))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(wordcloud.recolor(color_func=lambda *args, **kwargs:'white'), interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
